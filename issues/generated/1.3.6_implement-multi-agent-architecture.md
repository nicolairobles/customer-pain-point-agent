# 1.3.6 – Implement Multi-Agent Architecture

## Summary (Work Breakdown)

- **Description:** Introduce a multi-agent flow (planner/researcher → analyst) and harden agent execution across LangChain versions.
- **Work Package:** 2.3.x Agent Core Enhancements
- **Duration:** 4–8 hours
- **Story Points:** 5
- **Owner(s):** Stefan (primary), Nicolai (integration)

## Purpose

Move from a single “one-shot” agent response to a more reliable, staged workflow:
1) analyze the query, 2) collect raw evidence via tools, 3) synthesize a final report, and 4) optionally produce structured `pain_points`.

## What It Does (Current Behavior)

- **Query planning:** Uses `QueryProcessor` to produce a refined query, search terms, and suggested subreddits (`src/agent/query_processor.py`).
- **Research phase:** Builds a dynamic system prompt and runs a tool-using “Research Assistant” agent to collect raw findings (`src/agent/orchestrator.py`).
- **Analyst phase:** Runs a separate “Analyst” model to synthesize the research into a concise Markdown report (`src/agent/analyst.py`).
- **Structured extraction (wired):** When tool artifacts are available and `OPENAI_API_KEY` is set, converts tool outputs into extractor documents and returns JSON-serializable `pain_points` (`src/agent/orchestrator.py`, `src/extractors/pain_point_extractor.py`).
- **Telemetry:** Captures tool usage via a callback handler so the UI and metadata can show which tools were used (`src/agent/orchestrator.py`).

## What Was Done (Implemented Work)

- [x] Added staged multi-agent orchestration (research → analyst) with a dynamic system prompt.
- [x] Ensured Analyst uses its own LLM configuration with higher token limits to reduce truncation risk (`src/agent/analyst.py`).
- [x] Added robust extraction of tool outputs from common agent result shapes (`messages` / `intermediate_steps`) and surfaced structured `pain_points` when possible (`src/agent/orchestrator.py`).
- [x] Hardened compatibility around LangChain signature differences (e.g., `create_react_agent(model=...)` vs `llm=...`) and added/updated tests to validate this behavior (`tests/test_agent.py`).

## Acceptance Criteria

- [x] Agent executes in two stages (research collection, then synthesis).
- [x] Tool calls are observable (metadata indicates tool usage).
- [x] Output includes a human-readable report (`output`) and can include structured `pain_points` when tool artifacts + API key are available.
- [x] Unit tests cover orchestrator/tool-wiring behavior without live API calls.

## Notes / Follow-Ups

- **Multi-source aggregation (2.3.2)** is still separate work; 1.3.6 focuses on orchestration/architecture.
- The scope change removing Twitter/X was handled in separate issues/PRs; this story focuses on the agent architecture itself.

