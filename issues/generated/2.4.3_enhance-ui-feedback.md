# 2.4.3 – Enhance UI feedback and status messaging

## Summary (Work Breakdown)

- **Description:** Add loading states, partial results banners, and cost indicators
- **Work Package:** 3.4.3 UI Feedback Enhancements
- **Duration:** 2 hours
- **Story Points:** 3
- **Owner(s):** Al

- **Story Detail:** https://github.com/nicolairobles/customer-pain-point-agent/blob/master/docs/stories/2.4.3-enhance-ui-feedback.md

## Detailed Story

# Story 2.4.3 – Enhance UI feedback and status messaging

## Purpose
Improve user trust by surfacing clear loading indicators, partial results messaging, and cost estimations in the Streamlit app.

## Research Notes (Perplexity “Deep Research” style)
Perplexity’s “Deep Research” (now labeled “Research” in some UI) runs longer than a typical answer and makes the process legible by showing what it’s doing while it works (e.g., searching, reading sources) and surfacing source-level context as it progresses. The loading experience is intentionally “narrated” and changes as the system moves between steps and sources.

Reference: https://www.godofprompt.ai/blog/how-to-use-perplexity-ai-for-research

## Additional UX Best Practices (Dynamic Progress)
- Prefer a stable 4–7 phase model over raw low-level events; don’t “icon hop” on every tool callback.
- Avoid fake percent progress; use indeterminate progress with *evidence* (counts, domains, source titles).
- Debounce/throttle UI updates (target 250–500ms) and enforce a minimum visible time per phase (e.g., 1–2s) so changes feel intentional.
- Show an activity feed (“searched”, “reading”, “deduping”) and keep a steady “Now…” line; coalesce bursts of similar events.
- Never show contradictory states (e.g., “Done” + “Waiting for sources…”). If context is missing, fall back to a generic truth (“Collecting results…”).

## Acceptance Criteria
- [x] Introduce a prominent loading state while the agent runs, including estimated wait time when available.
- [x] Replace the single spinner with a “Research Progress” panel inspired by Perplexity Research mode:
  - [x] A primary status line that updates as the agent progresses (e.g., “Planning search…”, “Searching Reddit…”, “Searching the web…”, “Deduplicating results…”, “Extracting pain points…”, “Writing report…”).
  - [x] A compact step/timeline UI (at least 4–6 steps) with clear “active/completed” states.
  - [x] Each active step uses a minimalist dot indicator (no emoji/icons) with a subtle pulsing glow while active.
  - [x] When a tool returns URLs/domains, show “currently reviewing” context in the progress panel (domain + title when available) and keep a rolling list of the last N sources touched.
  - [x] Status messaging is driven by backend signals (tool callbacks + metadata) and degrades gracefully to generic messaging if granular context is unavailable (no “fake reading” states).
  - [x] Progress UI must be stable and human-paced:
    - [x] Phase indicator does not rapidly flicker between tools; minimum phase visibility is enforced.
    - [x] Updates are throttled/debounced (no rapid-fire text/icon flashing).
- [x] Display partial results banners when one or more sources fail, referencing Story 2.3.3 fallback messaging.
- [x] Show per-request API cost estimates sourced from instrumentation hooks when non-zero.
- [x] Error sections provide copy guidance and troubleshooting steps (e.g., refresh, adjust filters).
- [x] Update the loading experience + results page styling to match this visual direction:
  - [x] Futuristic light-mode with whitespace backgrounds.
  - [x] Minimalist linear-style, Attio-inspired gradient-border glassmorphism UI elements.
  - [x] Thin Inter typography (keep room for current purple accents).
  - [x] Neon-accented analytics/data-visualization styling for metrics without hurting readability (avoid excessive color noise).
- [x] Remove any “Deploy” button/CTA from the Streamlit UI (deployment should live in GitHub Actions/runbooks, not the app surface).
- [ ] UI strings reviewed for accessibility (contrast, ARIA labels) and documented in the style guide.

## Test Criteria
- [ ] **UI Test**: Capture screenshots/GIFs of loading (including the Research Progress panel updating across steps), success, partial failure, and error states.
- [ ] **Integration Test**: Trigger simulated tool failures and confirm banners align with backend signals.
- [ ] **Accessibility Review**: Run Streamlit’s accessibility checker (or manual audit) to validate contrast ratios and ARIA usage.
