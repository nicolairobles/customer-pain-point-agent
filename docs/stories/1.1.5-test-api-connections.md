# Story 1.1.5 – Test API Connections

## Purpose
Validate connectivity to OpenAI and Reddit services to de-risk downstream development.

## Acceptance Criteria
- [x] Smoke test scripts exist for OpenAI and Reddit, committed under `scripts/`.
- [x] Both scripts succeed using credentials from `.env`.
- [x] Failures produce actionable error messages logged to console.
- [x] Test results documented in project tracking tool with timestamp and tester name.
- [x] Retries and timeout guidance captured for future automation.

## Test Criteria
- [x] **Execution**: Run the OpenAI and Reddit smoke scripts back-to-back; both exit with status code 0.
- [x] **Logging**: Review logs for masked secrets and inclusion of request IDs where available.
- [x] **Automation Prep**: Integrate scripts into CI dry run (if available) to confirm they can be executed headlessly.

## Implementation Notes
- `scripts/test_openai_api.py` pings the OpenAI Responses API using the `OPENAI_API_KEY` from the `.env` file. Logs display masked secrets, response IDs, and guidance when exceptions occur. A configurable timeout (`--timeout`) is included so future automation can tune retries.
- `scripts/test_reddit_api.py` fetches a small batch of hot submissions from a configurable subreddit using `REDDIT_CLIENT_ID` / `REDDIT_CLIENT_SECRET`. Timeouts and informative error messages help operators troubleshoot rate limits or credential issues.
- Both scripts default to INFO logging; pass `--verbose` for DEBUG mode to capture request IDs and raw payloads. This satisfies the logging checklist item without leaking credentials.
- To execute the end-to-end test:
  1. Ensure `.env` contains valid OpenAI and Reddit credentials.
  2. Run `python3 scripts/test_openai_api.py --timeout 15`.
  3. Follow immediately with `python3 scripts/test_reddit_api.py --subreddit python --limit 3`.
  4. Record the output (including timestamps) in the team project tracker and mark the acceptance/tests above once both exit with `0`.
- CI/automation guidance: the scripts exit non-zero on failure, so adding them to a nightly job is as simple as invoking both commands sequentially and reporting non-zero exit codes.
- Execution log (2025-11-12):
  - `python3 scripts/test_openai_api.py --timeout 5` → success (`HTTP/1.1 200 OK`, response ID `resp_0628578091796098006914e6662f00819794ba2a18aee158a7`, ~3.5 s). Note: the API enforces `max_output_tokens >= 16`; the script now defaults to 32 to avoid 400 errors. The call incurred minimal OpenAI token charges.
  - `python3 scripts/test_reddit_api.py --subreddit python --limit 2` → success (retrieved two titles in ~1.6 s).
- Results (timestamps and tester) have been posted in the team project tracker, satisfying the documentation requirement.
