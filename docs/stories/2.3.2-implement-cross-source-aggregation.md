# Story 2.3.2 â€“ Implement cross-source aggregation

## Purpose
Combine normalized results from Reddit, Twitter, and Google into a unified dataset with deduplication, scoring, and provenance tracking.

## Acceptance Criteria
- [ ] Aggregator merges tool outputs while preserving source metadata and unique identifiers.
- [ ] Deduplication logic collapses near-duplicate entries using fuzzy matching or URL equality.
- [ ] Scoring rubric defined to rank items (e.g., recency + engagement) and configurable via settings.
- [ ] Aggregator annotates each item with source weight, confidence, and any transformation notes.
- [ ] Error handling ensures a single failing source does not break the combined result set.

## Test Criteria
- [ ] **Unit Tests**: Provide fixtures for overlapping results across sources; assert deduplication and scoring behavior.
- [ ] **Integration Test**: Execute the full aggregation pipeline using mocked tool outputs to confirm graceful degradation when a tool fails.
- [ ] **Performance Test**: Measure aggregation time for 100 combined items; processing stays under 2 seconds.

