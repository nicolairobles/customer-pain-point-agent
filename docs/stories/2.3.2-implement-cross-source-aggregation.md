# Story 2.3.2 â€“ Implement cross-source aggregation

## Purpose
Combine normalized results from Reddit and Google into a unified dataset with deduplication, scoring, and provenance tracking.

## Acceptance Criteria
- [x] Aggregator merges tool outputs while preserving source metadata and unique identifiers.
- [x] Deduplication logic collapses near-duplicate entries using fuzzy matching or URL equality.
- [x] Scoring rubric defined to rank items (e.g., recency + engagement) and configurable via settings.
- [x] Aggregator annotates each item with source weight, confidence, and any transformation notes.
- [x] Error handling ensures a single failing source does not break the combined result set.

## Test Criteria
- [x] **Unit Tests**: Provide fixtures for overlapping results across sources; assert deduplication and scoring behavior.
- [x] **Integration Test**: Execute the full aggregation pipeline using mocked tool outputs to confirm graceful degradation when a tool fails.
- [x] **Performance Test**: Measure aggregation time for 100 combined items; processing stays under 2 seconds.
